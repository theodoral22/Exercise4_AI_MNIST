Στόχος της εργασίας είναι η εκπαίδευση και αξιολόγηση νευρωνικών δικτύων για την ταξινόμηση ψηφίων από το dataset MNIST. Το MNIST περιλαμβάνει εικόνες χειρόγραφων ψηφίων (0-9) και αποτελεί πρότυπο πρόβλημα για την εκμάθηση και αξιολόγηση τεχνικών μηχανικής μάθησης και νευρωνικών δικτύων.
Σκοπός είναι να μελετηθεί η επίδραση διαφόρων παραμέτρων μοντέλου στην επίδραση του μοντέλου, όπως ο αριθμός και το μέγεθος των κρυφών επιπέδων, ο ρυθμός μάθησης, οι εποχές, η συνάρτηση ενεργοποίησης και το dropout.
Αρχικά, φορτώθηκαν τα δεδομένα MNIST, δηλαδή 60.000 εικόνες δοκιμής 28x28 pixels οι οποίες μετατράπηκαν σε μονοδιάστατα διανύσματα (28x28=784 χαρακτηριστικά) για να τροφοδοτηθούν στα πλήρως συνδεδεμένα νευρωνικά δίκτυα.
Στην συνέχεια, εμφανίστηκαν τυχαια επιλεγμένα ψηφία από το σετ εκπαίδευσης με τις αντίστοιχες κλάσεις τους.
Κατασκευάστηκαν διάφορα νευρωνικά δίκτυα με διαφορετικές παραμέτρους όπως:
1) Αριθμός κρυφών επιπέδων (1 έως 3)
2) Μέγεθος κρυφών επιπέδων (128 έως 512 νευρώνες)
3) Ρυθμός μάθησης (0.0005 έως 0.005)
4) Αριθμός εποχών εκπαίδευσης (10 έως 20)
5) Συνάρτηση ενεργοποίησης (tanh, relu, sigmoid)
Επιπλέον, χρησιμοποιήθηκε optimizer με κατηγορηματική απώλεια και για κάθε μοντέλο καταγράφηκε η τελική ακρίβεια στο validation set.
Τα αποτελέσματα των διαφορετικών μοντέλων αποθηκεύτηκαν σε πίνακα (DataFrame), όπου συγκρίθηκε η επίδραση με βάση τις παραμέτρους τους. Έτσι, εντοπίστηκαν και οπτικοποιήθηκαν παραδείγματα λανθασμένων προβλέψεων, δηλαδή εικόνων όπου η πρόβλεψη του μοντέλου δεν ταυτίστηκε με την πραγματική ετικέτα.
Τέλος, δημιουργήθηκε ένα νέο μοντέλο (Dropout) με τρία κρυφά επίπεδα και εφαρμογή dropout=0.3 μετά από κάθε επίπεδο για αποφυγή υπερπροσαρμογής (overfitting). Το μοντέλο αυτό εκπαιδεύτηκε για 15 εποχές με learning rate 0.001 και αξιολογήθηκε. Η αξιολόγηση έδειξε βελτίωση στην απόδοση, επιβεβαιώνοντας τη χρησιμότητα του dropout.

Τα συμπεράσματα που βγήκαν από την συγκεκριμένη εφαρμογή είναι τα εξής:
1) Η επιλογή συνάρτησης ενεργοποίησης και ρυθμού μάθησης επηρεάζει σημαντικά την ακρίβεια του μοντέλου.
2) Τα μεγαλύτερα και βαθύτερα νευρωνικά δίκτυα συνήθως αποδίδουν καλύτερα, αλλά με μεγαλύτερη πιθανότητα υπερπροσαρμογής.
3) Η χρήση dropout μειώνει την υπερπροσαρμογή και βελτιώνει την απόδοση στο validation set.
4) Το μοντέλο με dropout πέτυχε τελική ακρίβεια περίπου 0.962
